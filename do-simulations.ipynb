{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import itertools\n",
    "import matplotlib.pyplot as plt\n",
    "import json\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from sklearn.ensemble import GradientBoostingRegressor, GradientBoostingClassifier\n",
    "from itertools import chain\n",
    "import seaborn as sns\n",
    "import ray\n",
    "from sklearn.base import clone\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder\n",
    "from indirect_utils import (\n",
    "    DispatchEstimator,\n",
    "    fullspace,\n",
    "    generate_x_y,\n",
    "    get_delta,\n",
    "    logodds,\n",
    "    stratified_permute,\n",
    "    tologodds,\n",
    "    trimmed,\n",
    "    identity,\n",
    ")\n",
    "import random\n",
    "import math\n",
    "from tqdm import tqdm\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "residence_info = pd.read_csv(\"data/residence_info.csv\")\n",
    "\n",
    "\n",
    "def read_data(filename):\n",
    "    return (\n",
    "        pd.read_csv(filename)\n",
    "        .merge(residence_info[[\"residence\", \"elevation\"]], on=\"residence\", how=\"left\")\n",
    "        .sort_values([\"year_of_birth\", \"type\", \"sex\"])\n",
    "        .reset_index(drop=True)\n",
    "    )\n",
    "\n",
    "\n",
    "data_ITM = read_data(\"data/ITM.csv\")\n",
    "data_russian = read_data(\"data/russian.csv\").rename(columns={\"русский\": \"russian\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full = (\n",
    "    fullspace(data_ITM, [\"type\", \"sex\", \"residence\", \"year_of_birth\"])\n",
    "    .merge(residence_info, on=\"residence\", how=\"left\")\n",
    "    .sort_values([\"year_of_birth\", \"type\", \"sex\", \"residence\"])\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "russian_to_target = {True: \"russian\", False: \"number of lang\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ray.init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bootstrap_data(data):\n",
    "    return (\n",
    "        data.groupby(\"type\")\n",
    "        .apply(lambda x: x.sample(frac=1, replace=True))\n",
    "        .reset_index(drop=True)\n",
    "        .sort_values([\"year_of_birth\", \"type\"])\n",
    "        .reset_index(drop=True)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@ray.remote\n",
    "def predict_de(\n",
    "    data,\n",
    "    prediction_space,\n",
    "    estimator,\n",
    "    ct,\n",
    "    russian,\n",
    "    permute,\n",
    "    permute_strats=6,\n",
    "    delta=0,\n",
    "    seed=None,\n",
    "    bootstrap=False,\n",
    "):\n",
    "    \"\"\"\n",
    "    predict with DispatchEstimator\n",
    "    \n",
    "    == Params ==\n",
    "    - data: data to train\n",
    "    - prediction_space: values to predict on\n",
    "    - estimator: base estimator to construct DispatchEstimator\n",
    "    - ct: ColumnTransformer; make sure that first column is type\n",
    "    - russian: bool: will we predict Russian (otherwise ITM)\n",
    "    - permute: should we permute type before training\n",
    "    - permute_strats: number of strats to permute\n",
    "    - delta: simulated effect size; keep 0 if you want to simulate null distribution\n",
    "    - bootstrap: make a bootstrapped sample before training\n",
    "    \"\"\"\n",
    "\n",
    "    assert delta == 0 or not russian, \"delta supported only in ITM\"\n",
    "\n",
    "    assert not bootstrap or not permute, \"bootstrap and permute are mutually exclusive\"\n",
    "\n",
    "    if seed:\n",
    "        np.random.seed(seed)\n",
    "        random.seed(seed)\n",
    "\n",
    "    target = russian_to_target[russian]\n",
    "\n",
    "    prediction_space_adj = prediction_space[\n",
    "        [\"type\"] + list(data.drop(columns=[target, \"type\"]).columns)\n",
    "    ]\n",
    "\n",
    "    model = Pipeline(\n",
    "        [\n",
    "            (\"ct\", ct),  # make sure ct's first column is type\n",
    "            (\"estimator\", DispatchEstimator([clone(estimator), clone(estimator)])),\n",
    "        ]\n",
    "    )\n",
    "    if bootstrap:\n",
    "        data = bootstrap_data(data)\n",
    "\n",
    "    if permute:\n",
    "        type_new = stratified_permute(data[\"type\"], strats=permute_strats)\n",
    "    else:\n",
    "        type_new = data[\"type\"]\n",
    "\n",
    "    data_permuted = pd.concat(\n",
    "        [\n",
    "            type_new.reset_index(drop=True),\n",
    "            data.drop(columns=[\"type\"]).reset_index(drop=True),\n",
    "        ],\n",
    "        axis=1,\n",
    "    )\n",
    "\n",
    "    if delta != 0:\n",
    "        data_permuted.loc[data_permuted[\"type\"] == 0, target] += delta / 2\n",
    "        data_permuted.loc[data_permuted[\"type\"] == 1, target] -= delta / 2\n",
    "\n",
    "    model.fit(data_permuted.drop(columns=[target]), data_permuted[target])\n",
    "\n",
    "    if russian:\n",
    "        pred = model.predict_proba(prediction_space_adj)[:, 1]\n",
    "    else:\n",
    "        pred = model.predict(prediction_space_adj)\n",
    "\n",
    "    return pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def permutation_delta(\n",
    "    data,\n",
    "    prediction_space,\n",
    "    estimator,\n",
    "    number_of_permutations,\n",
    "    russian,\n",
    "    ct,\n",
    "    statistics=(identity,),\n",
    "    null_delta=0,\n",
    "    groupby_columns=(\"year_of_birth\",),\n",
    "    use_logodds=False,\n",
    "    iter_offset=0,\n",
    "    bootstrap=False,\n",
    "    seed=42,\n",
    "):\n",
    "    stat_names = [\"delta_\" + stat.__name__ for stat in statistics]\n",
    "\n",
    "    groupby_columns = list(groupby_columns)\n",
    "\n",
    "    r = []\n",
    "\n",
    "    predictions_futures = [\n",
    "        predict_de.remote(\n",
    "            data,\n",
    "            prediction_space,\n",
    "            estimator,\n",
    "            ct,\n",
    "            russian,\n",
    "            permute=not bootstrap,\n",
    "            delta=null_delta,\n",
    "            bootstrap=bootstrap,\n",
    "            seed=i + iter_offset + seed,\n",
    "        )\n",
    "        for i in range(number_of_permutations)\n",
    "    ]\n",
    "\n",
    "    predictions = ray.get(predictions_futures)\n",
    "\n",
    "    r = [\n",
    "        prediction_space[[\"type\"] + groupby_columns].assign(\n",
    "            pred=pred, iter=[it] * prediction_space.shape[0]\n",
    "        )\n",
    "        for it, pred in enumerate(predictions, start=iter_offset)\n",
    "    ]\n",
    "\n",
    "    results = pd.concat(r, axis=0).reset_index(drop=True)\n",
    "    results.columns = list([\"type\"] + groupby_columns) + [\"pred\", \"iter\"]\n",
    "\n",
    "    delta = (\n",
    "        get_delta(results, use_logodds=use_logodds)\n",
    "        .assign(\n",
    "            **{\n",
    "                stat_name: lambda x, stat=stat: stat(x[\"delta\"])\n",
    "                for stat_name, stat in zip(stat_names, statistics)\n",
    "            }\n",
    "        )[groupby_columns + stat_names + [\"iter\"]]\n",
    "        .groupby(groupby_columns + [\"iter\"])\n",
    "        .mean()\n",
    "        .reset_index()\n",
    "    )\n",
    "    return delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat_wrap(\n",
    "    f, number_of_permutations, *args, permutations_per_iteration=1000, **kwargs\n",
    "):\n",
    "    assert number_of_permutations % permutations_per_iteration == 0\n",
    "\n",
    "    number_of_splits = number_of_permutations // permutations_per_iteration\n",
    "    return pd.concat(\n",
    "        [\n",
    "            f(\n",
    "                *args,\n",
    "                number_of_permutations=permutations_per_iteration,\n",
    "                iter_offset=i * permutations_per_iteration,\n",
    "                **kwargs\n",
    "            )\n",
    "            for i in tqdm(range(number_of_splits))\n",
    "        ],\n",
    "        axis=0,\n",
    "    ).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ITM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_deltas_and_full_pred(\n",
    "    data,\n",
    "    estimator,\n",
    "    data_real,\n",
    "    data_cat,\n",
    "    number_of_permutations,\n",
    "    russian,\n",
    "    null_delta=0,\n",
    "    permutations_per_iteration=1000,\n",
    "    bootstrap=False,\n",
    "):\n",
    "\n",
    "    target = russian_to_target[russian]\n",
    "\n",
    "    data = data[data_real + data_cat + [target]]\n",
    "\n",
    "    ct = ColumnTransformer(\n",
    "        [(\"real\", \"passthrough\", data_real), (\"catenc\", OneHotEncoder(), data_cat)],\n",
    "        sparse_threshold=0,\n",
    "    )\n",
    "\n",
    "    full_pred = full.assign(\n",
    "        pred=lambda x: predict_de._function(\n",
    "            data, x, estimator, ct, russian, permute=False, seed=42\n",
    "        )\n",
    "    )\n",
    "\n",
    "    def get_deltas(bootstrap):\n",
    "        return concat_wrap(\n",
    "            permutation_delta,\n",
    "            number_of_permutations=number_of_permutations,\n",
    "            permutations_per_iteration=permutations_per_iteration,\n",
    "            data=data,\n",
    "            prediction_space=full,\n",
    "            estimator=estimator,\n",
    "            russian=russian,\n",
    "            ct=ct,\n",
    "            null_delta=null_delta,\n",
    "            statistics=(identity, np.abs),\n",
    "            use_logodds=russian,\n",
    "            bootstrap=bootstrap,\n",
    "        ).rename(columns={\"delta_identity\": \"delta\"})\n",
    "\n",
    "    return get_deltas(bootstrap=False), get_deltas(bootstrap=True), full_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_of_permutations = 10000\n",
    "permutations_per_iteration = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "delta_ITM_perm, delta_ITM_bootstrap, pred_ITM_full = get_deltas_and_full_pred(\n",
    "    data=data_ITM,\n",
    "    estimator=GradientBoostingRegressor(max_depth=4, n_estimators=100),\n",
    "    data_cat=[\"mother tongue\", \"residence\"],\n",
    "    data_real=[\"type\", \"year_of_birth\", \"language population\", \"village population\"],\n",
    "    number_of_permutations=number_of_permutations,\n",
    "    permutations_per_iteration=permutations_per_iteration,\n",
    "    russian=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_ITM_perm.to_csv(\"delta_itm_perm_gbr.csv\", index=False)\n",
    "delta_ITM_bootstrap.to_csv(\"delta_itm_bootstrap_gbr.csv\", index=False)\n",
    "pred_ITM_full.to_csv(\"pred_itm_full_gbr.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    delta_russian_perm,\n",
    "    delta_russian_bootstrap,\n",
    "    pred_russian_full,\n",
    ") = get_deltas_and_full_pred(\n",
    "    data=data_russian,\n",
    "    estimator=GradientBoostingClassifier(max_depth=1, n_estimators=150),\n",
    "    data_cat=[\"mother tongue\", \"sex\"],\n",
    "    data_real=[\n",
    "        \"type\",\n",
    "        \"year_of_birth\",\n",
    "        \"language population\",\n",
    "        \"elevation\",\n",
    "        \"village population\",\n",
    "    ],\n",
    "    number_of_permutations=number_of_permutations,\n",
    "    permutations_per_iteration=permutations_per_iteration,\n",
    "    russian=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "delta_russian_perm.to_csv(\"delta_russian_perm_gbr.csv\", index=False)\n",
    "delta_russian_bootstrap.to_csv(\"delta_russian_bootstrap_gbr.csv\", index=False)\n",
    "pred_russian_full.to_csv(\"pred_russian_full_gbr.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
